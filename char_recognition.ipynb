{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import shutil\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "import albumentations as A\n",
    "from albumentations.core.transforms_interface import DualTransform\n",
    "import random\n",
    "from YOLODetector import YOLODetector\n",
    "from CharClassifier import CharClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "import sys\n",
    "del sys.modules['utils']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tạo thư mục data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.mkdir(\"character_recognition/data\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "ALPHA_DICT = {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9',\n",
    "    10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G', 17: 'H', 18: 'K', 19: 'L',\n",
    "    20: 'M', 21: 'N', 22: 'P', 23: 'R', 24: 'S', 25: 'T', 26: 'U', 27: 'V', 28: 'X', 29: 'Y', 30: 'Z'}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "for c in ALPHA_DICT.values():\n",
    "    os.mkdir(\"character_recognition/data/\"+c)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tách chiết data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "source_path = \"lp_detection/bike_data/\"\n",
    "dest_path = \"character_recognition/crop/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "lst_im = os.listdir(source_path)\n",
    "lst_im = [file for file in lst_im if len(file) > 10 and file[-3:] == 'jpg']\n",
    "len(lst_im)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1740"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "for file in lst_im:\n",
    "    img = cv2.imread(source_path+file)\n",
    "    box, _ = read_yolo_content(source_path+file[:-3]+\"txt\")\n",
    "    box = box[0]\n",
    "    cv2.imwrite(dest_path+file, crop_im(img, box))\n",
    "    #break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sinh ký tự"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "chr_det = YOLODetector('character_detection/yolov4-tiny-char-detect_last.weights', 'character_detection/yolov4-tiny-char-detect.cfg', confi_thres=0.7)\n",
    "chr_cls = CharClassifier('character_recognition/myCNN_backup_28_BN.h5')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-10-02 22:10:26.334533: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-10-02 22:10:26.334806: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "random.shuffle(lst_im)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "char_count = dict(zip(ALPHA_DICT.values(), [0]*len(ALPHA_DICT)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "source_path = \"character_recognition/crop/\"\n",
    "dest_path = \"character_recognition/data/\"\n",
    "MAX_COUNT = 50\n",
    "\n",
    "for file in lst_im[1500:]:\n",
    "    img = cv2.imread(source_path+file)\n",
    "\n",
    "    crop_resize = resize_with_ratio(img, 100/img.shape[1])\n",
    "    ori_lp = cv2.GaussianBlur(crop_resize, (5,5), 1.0)\n",
    "    \n",
    "    crop_resize = cv2.resize(img, (100, 100))\n",
    "    resz_lp = cv2.GaussianBlur(crop_resize, (5,5), 1.0)\n",
    "\n",
    "    bboxes = chr_det.detect(resz_lp)\n",
    "    bboxes = [list(bbox) for bbox in bboxes]\n",
    "\n",
    "    characters = []\n",
    "    for bbox in bboxes:\n",
    "        pad_bbox = bbox.copy()\n",
    "        pad_bbox[2] += 0.05\n",
    "        pad_bbox[3] += 0.05\n",
    "        new_im = crop_im(ori_lp, pad_bbox)\n",
    "        new_im = cv2.cvtColor(new_im, cv2.COLOR_BGR2GRAY)\n",
    "        new_im = resize_with_ratio(new_im, 28/new_im.shape[0])\n",
    "        border = 28-new_im.shape[1]\n",
    "        if border % 2 == 0:\n",
    "            border_L = border_R = border // 2\n",
    "        else:\n",
    "            border_L = border // 2\n",
    "            border_R = border_L + 1\n",
    "        if border > 0:\n",
    "            new_im = cv2.copyMakeBorder(new_im, 0, 0, border_L, border_R, cv2.BORDER_REPLICATE)\n",
    "        else:\n",
    "            new_im = cv2.resize(new_im, (28,28))\n",
    "        characters.append(new_im)\n",
    "    \n",
    "    pred_chars = chr_cls.predict(characters)\n",
    "\n",
    "    for c, lab in zip(characters, pred_chars):\n",
    "        if char_count[lab] == MAX_COUNT:\n",
    "            continue\n",
    "        cv2.imwrite(dest_path+lab+\"/\"+str(char_count[lab])+\".jpg\", c)\n",
    "        char_count[lab] += 1\n",
    "\n",
    "    #break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "file_count = 0\n",
    "for root, subFolders, files in os.walk(\"character_recognition/data/\"):\n",
    "    for file in files:\n",
    "        if file[-3:] == 'jpg':\n",
    "            newname = \"char\" + str(file_count) + \".jpg\"\n",
    "            os.rename(root+\"/\"+file, root+\"/\"+newname)\n",
    "            file_count += 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "file_count"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1275"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Chia tập train val"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data_ls = []\n",
    "\n",
    "for root, subFolders, files in os.walk(\"character_recognition/data/\"):\n",
    "    for file in files:\n",
    "        if file[-3:] == 'jpg':\n",
    "            data_ls.append((file, root[-1]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "data_ls_df = pd.DataFrame(data_ls, columns=['Image', \"Class\"])\n",
    "data_ls_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>char10.jpg</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>char11.jpg</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>char13.jpg</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>char12.jpg</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>char16.jpg</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>char1250.jpg</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>char1246.jpg</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>char1252.jpg</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>char1253.jpg</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>char1247.jpg</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1274 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Image Class\n",
       "0       char10.jpg     R\n",
       "1       char11.jpg     R\n",
       "2       char13.jpg     R\n",
       "3       char12.jpg     R\n",
       "4       char16.jpg     R\n",
       "...            ...   ...\n",
       "1269  char1250.jpg     P\n",
       "1270  char1246.jpg     P\n",
       "1271  char1252.jpg     P\n",
       "1272  char1253.jpg     P\n",
       "1273  char1247.jpg     P\n",
       "\n",
       "[1274 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    data_ls_df.Image, data_ls_df.Class,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=data_ls_df.Class\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "val_df = pd.concat([X_val, y_val], axis=1)\n",
    "train_df.to_csv(\"character_recognition/train.csv\", index=False)\n",
    "val_df.to_csv(\"character_recognition/val.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!mkdir character_recognition/data_splitted"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "os.mkdir(\"character_recognition/data_splitted/train/\")\n",
    "os.mkdir(\"character_recognition/data_splitted/val/\")\n",
    "for c in ALPHA_DICT.values():\n",
    "    os.mkdir(\"character_recognition/data_splitted/train/\"+c)\n",
    "    os.mkdir(\"character_recognition/data_splitted/val/\"+c)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_df = pd.read_csv(\"character_recognition/train.csv\")\n",
    "val_df = pd.read_csv(\"character_recognition/val.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "dest_path = \"character_recognition/data_splitted/\"\n",
    "source_path = \"character_recognition/data/\"\n",
    "\n",
    "for item in train_df.values:\n",
    "    name, lab = list(item)\n",
    "    shutil.copyfile(source_path+lab+\"/\"+name, dest_path+\"train/\"+lab+\"/\"+name)\n",
    "    #break\n",
    "\n",
    "for item in val_df.values:\n",
    "    name, lab = list(item)\n",
    "    shutil.copyfile(source_path+lab+\"/\"+name, dest_path+\"val/\"+lab+\"/\"+name)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}